# backend/stt_tts/text_to_speech.py
"""
Text-to-Speech –º–æ–¥—É–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Silero TTS.
100% on-premise, —Ä–∞–±–æ—Ç–∞–µ—Ç offline.
"""

import torch
import re
from num2words import num2words
import logging
import os

logger = logging.getLogger(__name__)

SPEAKER_MAPPING = {
    "xenia": "kseniya",
    "kseniya": "kseniya",
    "aidar": "aidar",
    "baya": "baya",
    "irina": "irina",
    "natasha": "natasha",
    "ruslan": "ruslan",
    "eugene": "ruslan",
}


class TextToSpeech:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é Silero TTS."""

    def __init__(
            self,
            language: str = "ru",
            speaker: str = "kseniya",
            device: str = None
    ):
        """
        Args:
            language: —è–∑—ã–∫ ('ru', 'en', 'de', 'es', 'fr')
            speaker: –≥–æ–ª–æ—Å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ:
                - 'kseniya' (–∂–µ–Ω—Å–∫–∏–π) - –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø
                - 'aidar' (–º—É–∂—Å–∫–æ–π)
                - 'baya' (–∂–µ–Ω—Å–∫–∏–π)
                - 'irina' (–∂–µ–Ω—Å–∫–∏–π)
                - 'natasha' (–∂–µ–Ω—Å–∫–∏–π)
                - 'ruslan' (–º—É–∂—Å–∫–æ–π)
            device: 'cuda' –∏–ª–∏ 'cpu'
        """
        self.language = language

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–º—è
        if speaker in SPEAKER_MAPPING:
            self.speaker = SPEAKER_MAPPING[speaker]
            logger.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: {speaker} -> {self.speaker}")
        else:
            self.speaker = speaker

        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")

        logger.info(f"üîä –ó–∞–≥—Ä—É–∑–∫–∞ Silero TTS ({language}, speaker={self.speaker})...")

        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º—É—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ torch.package
            # –°—Å—ã–ª–∫–∏ –Ω–∞ –º–æ–¥–µ–ª–∏: https://models.silero.ai/models/tts/
            model_urls = {
                'ru': 'https://models.silero.ai/models/tts/ru/v4_ru.pt',
                'en': 'https://models.silero.ai/models/tts/en/v3_en.pt',
                'de': 'https://models.silero.ai/models/tts/de/v3_de.pt',
                'es': 'https://models.silero.ai/models/tts/es/v3_es.pt',
                'fr': 'https://models.silero.ai/models/tts/fr/v3_fr.pt',
            }

            if language not in model_urls:
                raise ValueError(f"–Ø–∑—ã–∫ '{language}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –î–æ—Å—Ç—É–ø–Ω—ã: {list(model_urls.keys())}")

            # –ü—É—Ç—å –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
            cache_dir = os.path.expanduser('~/.cache/silero_tts')
            os.makedirs(cache_dir, exist_ok=True)

            model_path = os.path.join(cache_dir, f'v4_{language}.pt')

            # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            if not os.path.isfile(model_path):
                logger.info(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ {language} (~100MB)...")
                torch.hub.download_url_to_file(model_urls[language], model_path)
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞")
            else:
                logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ torch.package
            self.model = torch.package.PackageImporter(model_path).load_pickle("tts_models", "model")
            self.model.to(self.device)

            self.sample_rate = 48000

            logger.info(f"‚úÖ Silero TTS –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {language}/{self.speaker} –Ω–∞ {self.device}")
            logger.info(f"   –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {self.sample_rate} Hz")
            logger.info(f"   –¢–∏–ø –º–æ–¥–µ–ª–∏: {type(self.model)}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Silero TTS: {e}")
            raise

    def preprocess_text(self, text: str) -> str:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞."""
        if not text:
            return ""

        if self.language == "ru":
            def replace_number(match):
                num = match.group(0)
                try:
                    return num2words(int(num), lang='ru')
                except:
                    return num

            text = re.sub(r'\b\d+\b', replace_number, text)

            abbreviations = {
                "–ü–ê–û": "–ø—É–±–ª–∏—á–Ω–æ–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ",
                "–ê–û": "–∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ",
                "–û–û–û": "–æ–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é",
                "–∫–º": "–∫–∏–ª–æ–º–µ—Ç—Ä–æ–≤",
                "–º¬≥": "–∫—É–±–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–æ–≤",
                "—Ç—ã—Å.": "—Ç—ã—Å—è—á",
                "–º–ª–Ω": "–º–∏–ª–ª–∏–æ–Ω–æ–≤",
                "–º–ª—Ä–¥": "–º–∏–ª–ª–∏–∞—Ä–¥–æ–≤",
                "—Ç.": "—Ç–æ–Ω–Ω",
            }

            for abbr, full in abbreviations.items():
                text = re.sub(r'\b' + re.escape(abbr) + r'\b', full, text, flags=re.IGNORECASE)

        return text

    def synthesize(
            self,
            text: str,
            output_path: str = None,
            preprocess: bool = True
    ) -> torch.Tensor:
        """–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        if not text or not text.strip():
            logger.warning("–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")
            return torch.tensor([])

        if preprocess:
            text = self.preprocess_text(text)

        logger.info(f"üîä –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏: {text[:100]}...")

        try:
            # –í—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏
            audio = self.model.apply_tts(
                text=text,
                speaker=self.speaker,
                sample_rate=self.sample_rate
            )

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ tensor
            if not isinstance(audio, torch.Tensor):
                import numpy as np
                if isinstance(audio, np.ndarray):
                    audio = torch.from_numpy(audio)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            if output_path and len(audio) > 0:
                import soundfile as sf

                audio_np = audio.cpu().numpy() if isinstance(audio, torch.Tensor) else audio

                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                if abs(audio_np).max() > 1.0:
                    audio_np = audio_np / abs(audio_np).max()

                sf.write(output_path, audio_np, self.sample_rate)
                logger.info(f"‚úÖ –ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path} ({os.path.getsize(output_path)} bytes)")

            logger.info(f"‚úÖ –°–∏–Ω—Ç–µ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(audio)} —Å—ç–º–ø–ª–æ–≤")

            return audio

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞: {e}", exc_info=True)
            raise


# Singleton
_tts_instance = None


def get_tts_instance(speaker: str = "xenia", language: str = "ru") -> TextToSpeech:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä TTS."""
    global _tts_instance

    real_speaker = SPEAKER_MAPPING.get(speaker, speaker)

    if _tts_instance is not None:
        if _tts_instance.speaker == real_speaker and _tts_instance.language == language:
            return _tts_instance

    _tts_instance = TextToSpeech(language=language, speaker=speaker)
    return _tts_instance


def list_available_speakers() -> dict:
    """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤."""
    return {
        "ru": [
            {"name": "xenia", "real_name": "kseniya", "gender": "female", "recommended": True},
            {"name": "kseniya", "real_name": "kseniya", "gender": "female", "recommended": True},
            {"name": "aidar", "real_name": "aidar", "gender": "male", "recommended": True},
            {"name": "baya", "real_name": "baya", "gender": "female", "recommended": False},
            {"name": "irina", "real_name": "irina", "gender": "female", "recommended": False},
            {"name": "natasha", "real_name": "natasha", "gender": "female", "recommended": False},
            {"name": "ruslan", "real_name": "ruslan", "gender": "male", "recommended": False},
        ]
    }


# –¢–µ—Å—Ç
if __name__ == "__main__":
    import sys

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï TEXT-TO-SPEECH\n")

    try:
        tts = get_tts_instance(speaker="xenia")
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {type(tts.model)}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    test_texts = [
        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø —Ü–∏—Ñ—Ä–æ–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ü–ê–û –¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å.",
        "–¢–µ—Å—Ç —Ä–∞–±–æ—Ç—ã —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏.",
    ]

    for i, text in enumerate(test_texts, 1):
        print(f"\n–¢–µ—Å—Ç {i}: {text}")
        output_file = f"test_tts_{i}.wav"

        try:
            audio = tts.synthesize(text, output_path=output_file, preprocess=True)
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_file} ({len(audio)} —Å—ç–º–ø–ª–æ–≤)")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback

            traceback.print_exc()

    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–∏—Ç–µ WAV —Ñ–∞–π–ª—ã.\n")
